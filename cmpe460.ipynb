{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeawsiuz5XPP"
      },
      "outputs": [],
      "source": [
        "# We are importing librarires here\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import pandas as pd\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing datasets\n",
        "!wget http://www.manythings.org/anki/mar-eng.zip -O mar-eng.zip\n",
        "!unzip mar-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbSiaARe6mWn",
        "outputId": "bb7d0040-cfa5-46e9-cee9-3c007d076fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-22 14:38:17--  http://www.manythings.org/anki/mar-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458910 (1.4M) [application/zip]\n",
            "Saving to: ‘mar-eng.zip’\n",
            "\n",
            "mar-eng.zip         100%[===================>]   1.39M  6.01MB/s    in 0.2s    \n",
            "\n",
            "2023-01-22 14:38:18 (6.01 MB/s) - ‘mar-eng.zip’ saved [1458910/1458910]\n",
            "\n",
            "Archive:  mar-eng.zip\n",
            "  inflating: mar.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading data\n",
        "#This code is reading in a file called \"mar.txt\" and creating a DataFrame named \"lines\" with two columns, \"eng\" and \"mar\", using the read_table method from the pandas library.\n",
        "lines = pd.read_table( 'mar.txt' , names=[ 'eng' , 'mar' ] )\n",
        "lines.reset_index( level=0 , inplace=True )\n",
        "lines.rename( columns={ 'index' : 'eng' , 'eng' : 'mar' , 'mar' : 'c' } , inplace=True )\n",
        "lines = lines.drop( 'c' , 1 )\n",
        "lines = lines.iloc[ 10000 : 20000 ] \n",
        "lines.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "cMgvY7r76qut",
        "outputId": "dc768849-bbcd-4a40-bb47-127c7bcaf934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-5840d881011a>:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  lines = lines.drop( 'c' , 1 )\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       eng                 mar\n",
              "10000  Everything changes.         सगळं बदलतं.\n",
              "10001  Everything is fine.  सगळं काही ठीक आहे.\n",
              "10002  Everything is fine.  सर्व काही ठीक आहे.\n",
              "10003  Exercise every day.   दररोज व्यायाम कर.\n",
              "10004  Exercise every day.  दररोज व्यायाम करा."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49914447-fe25-4b55-915e-d65dc76275aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>mar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>Everything changes.</td>\n",
              "      <td>सगळं बदलतं.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>Everything is fine.</td>\n",
              "      <td>सगळं काही ठीक आहे.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>Everything is fine.</td>\n",
              "      <td>सर्व काही ठीक आहे.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10003</th>\n",
              "      <td>Exercise every day.</td>\n",
              "      <td>दररोज व्यायाम कर.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10004</th>\n",
              "      <td>Exercise every day.</td>\n",
              "      <td>दररोज व्यायाम करा.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49914447-fe25-4b55-915e-d65dc76275aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49914447-fe25-4b55-915e-d65dc76275aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49914447-fe25-4b55-915e-d65dc76275aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing input data for the Encoder\n",
        "#Now we have the tokenized and padded English lines in the encoder_input_data variable. This is the input for the encoder of your neural machine translation model.\n",
        "#We also have the eng_word_dict, which is a dictionary containing the English words and their corresponding index, and num_eng_tokens which is the number of unique English tokens.\n",
        "eng_lines = list()\n",
        "for line in lines.eng:\n",
        "    eng_lines.append( line ) \n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts( eng_lines ) \n",
        "tokenized_eng_lines = tokenizer.texts_to_sequences( eng_lines ) \n",
        "\n",
        "length_list = list()\n",
        "for token_seq in tokenized_eng_lines:\n",
        "    length_list.append( len( token_seq ))\n",
        "max_input_length = np.array( length_list ).max()\n",
        "print( 'English max length is {}'.format( max_input_length ))\n",
        "\n",
        "padded_eng_lines = preprocessing.sequence.pad_sequences( tokenized_eng_lines , maxlen=max_input_length , padding='post' )\n",
        "encoder_input_data = np.array( padded_eng_lines )\n",
        "print( 'Encoder input data shape -> {}'.format( encoder_input_data.shape ))\n",
        "\n",
        "eng_word_dict = tokenizer.word_index\n",
        "num_eng_tokens = len( eng_word_dict )+1\n",
        "print( 'Number of English tokens = {}'.format( num_eng_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm5Dm_b66vEm",
        "outputId": "43d69a2e-2ec3-492b-eb55-0a89636e931e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English max length is 7\n",
            "Encoder input data shape -> (10000, 7)\n",
            "Number of English tokens = 2382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing input data for the Decoder\n",
        "#Now, we have tokenized and padded the input English and Marathi sentences. encoder_input_data is the padded input English sentences and decoder_input_data is the padded input Marathi sentences. eng_word_dict is the dictionary of English words and their corresponding index and num_eng_tokens is the number of unique English tokens.\n",
        "#Similarly, mar_word_dict is the dictionary of Marathi words and their corresponding index and num_mar_tokens is the number of unique Marathi tokens.\n",
        "mar_lines = list()\n",
        "for line in lines.mar:\n",
        "    mar_lines.append( '<START> ' + line + ' <END>' )  \n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts( mar_lines ) \n",
        "tokenized_mar_lines = tokenizer.texts_to_sequences( mar_lines ) \n",
        "\n",
        "length_list = list()\n",
        "for token_seq in tokenized_mar_lines:\n",
        "    length_list.append( len( token_seq ))\n",
        "max_output_length = np.array( length_list ).max()\n",
        "print( 'Marathi max length is {}'.format( max_output_length ))\n",
        "\n",
        "padded_mar_lines = preprocessing.sequence.pad_sequences( tokenized_mar_lines , maxlen=max_output_length, padding='post' )\n",
        "decoder_input_data = np.array( padded_mar_lines )\n",
        "print( 'Decoder input data shape -> {}'.format( decoder_input_data.shape ))\n",
        "\n",
        "mar_word_dict = tokenizer.word_index\n",
        "num_mar_tokens = len( mar_word_dict )+1\n",
        "print( 'Number of Marathi tokens = {}'.format( num_mar_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud2Iq4wj6yO3",
        "outputId": "72c3a711-152e-4044-df6b-b985b691722f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marathi max length is 11\n",
            "Decoder input data shape -> (10000, 11)\n",
            "Number of Marathi tokens = 4771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing target data for the Decoder \n",
        "#This code is preprocessing the data for a machine translation model using the Encoder-Decoder architecture. The first half of the code preprocesses the English sentences in the dataset and tokenizes them, and pads the tokenized sequences to make them of the same length.\n",
        "#It also creates a word dictionary for English words and finds the maximum length of the English sentences. The second half of the code preprocesses the Marathi sentences in the dataset and tokenizes them, and pads the tokenized sequences to make them of the same length.\n",
        "#It also creates a word dictionary for Marathi words and finds the maximum length of the Marathi sentences. The code also creates one-hot encoded target data for the decoder by removing the first element of the tokenized Marathi sentences and padding the resulting sequences to make them of the same length as the padded input sequences.\n",
        "decoder_target_data = list()\n",
        "for token_seq in tokenized_mar_lines:\n",
        "    decoder_target_data.append( token_seq[ 1 : ] ) \n",
        "    \n",
        "padded_mar_lines = preprocessing.sequence.pad_sequences( decoder_target_data , maxlen=max_output_length, padding='post' )\n",
        "onehot_mar_lines = utils.to_categorical( padded_mar_lines , num_mar_tokens )\n",
        "decoder_target_data = np.array( onehot_mar_lines )\n",
        "print( 'Decoder target data shape -> {}'.format( decoder_target_data.shape ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RbWylct62zL",
        "outputId": "0fc37565-7635-4b43-bfb9-1176b1849465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder target data shape -> (10000, 11, 4771)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the Encoder-Decoder model\n",
        "#This code defines a neural network architecture for a sequence-to-sequence (Seq2Seq) model using the TensorFlow library. The architecture consists of an encoder and a decoder.\n",
        "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
        "encoder_embedding = tf.keras.layers.Embedding( num_eng_tokens, 256 , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 128 , return_state=True  )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( num_mar_tokens, 256 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( 128 , return_state=True , return_sequences=True)\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( num_mar_tokens , activation=tf.keras.activations.softmax ) \n",
        "output = decoder_dense ( decoder_outputs )\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b0XacZb67vM",
        "outputId": "bc239397-a28a-406e-d364-54f9b09063d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    609792      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    1221376     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 128),        197120      ['embedding[0][0]']              \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 128),  197120      ['embedding_1[0][0]',            \n",
            "                                 (None, 128),                     'lstm[0][1]',                   \n",
            "                                 (None, 128)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 4771)   615459      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,840,867\n",
            "Trainable params: 2,840,867\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This code will train the encoder-decoder model on the given dataset of English and Marathi sentences. The encoder input is the English sentence and the decoder input is the Marathi sentence with <START> and <END> tokens added.\n",
        "#The decoder target is the Marathi sentence with the <START> token removed. The model is trained for 50 epochs with a batch size of 250. After training, the model is saved to a file named 'model.h5'.\n",
        "model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=250, epochs=50 ) \n",
        "model.save( 'model.h5' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdWckOrW6_xp",
        "outputId": "b33441ec-54b1-44c1-f496-f247f126bf19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 26s 469ms/step - loss: 3.2304\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 18s 455ms/step - loss: 2.6215\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 19s 487ms/step - loss: 2.4557\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 18s 456ms/step - loss: 2.3207\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 2.2114\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 18s 460ms/step - loss: 2.1249\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 18s 461ms/step - loss: 2.0501\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 19s 476ms/step - loss: 1.9790\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 19s 465ms/step - loss: 1.9105\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 19s 466ms/step - loss: 1.8448\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 19s 468ms/step - loss: 1.7800\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 19s 473ms/step - loss: 1.7172\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 19s 463ms/step - loss: 1.6558\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 18s 462ms/step - loss: 1.5987\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 18s 458ms/step - loss: 1.5422\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 18s 460ms/step - loss: 1.4878\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 19s 467ms/step - loss: 1.4333\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 19s 469ms/step - loss: 1.3821\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 19s 467ms/step - loss: 1.3304\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 1.2818\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 19s 463ms/step - loss: 1.2329\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 18s 462ms/step - loss: 1.1868\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 19s 468ms/step - loss: 1.1400\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 21s 534ms/step - loss: 1.0952\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 20s 500ms/step - loss: 1.0519\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 20s 495ms/step - loss: 1.0086\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 19s 468ms/step - loss: 0.9669\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 0.9263\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 21s 536ms/step - loss: 0.8868\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 19s 483ms/step - loss: 0.8497\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 21s 518ms/step - loss: 0.8123\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 19s 479ms/step - loss: 0.7775\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 20s 491ms/step - loss: 0.7425\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 19s 486ms/step - loss: 0.7100\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 21s 508ms/step - loss: 0.6785\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 21s 535ms/step - loss: 0.6488\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 19s 473ms/step - loss: 0.6200\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 19s 466ms/step - loss: 0.5916\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 19s 473ms/step - loss: 0.5658\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 19s 471ms/step - loss: 0.5408\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 19s 466ms/step - loss: 0.5167\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 19s 479ms/step - loss: 0.4924\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 19s 465ms/step - loss: 0.4712\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 19s 465ms/step - loss: 0.4492\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 18s 456ms/step - loss: 0.4297\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 18s 443ms/step - loss: 0.4097\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 18s 461ms/step - loss: 0.3917\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 18s 452ms/step - loss: 0.3742\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 18s 448ms/step - loss: 0.3577\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 0.3417\n"
          ]
        }
      ]
    }
  ]
}